#!/usr/bin/env python

import os
import argparse
import logging

from gwf.parser import parse
from gwf.task_scheduler import TaskScheduler
from gwf.process_scheduler import ProcessScheduler
from gwf.reporting import FileReporter

from gwf.environment import get_environment

parser = argparse.ArgumentParser(description='Run a workflow locally.')

parser.add_argument('-f', '--file',
                    default='workflow.gwf', dest='workflow_file',
                    help='workflow file if not the default (workflow.gwf).')

group = parser.add_mutually_exclusive_group()

group.add_argument('-a', '--all', default=False, action='store_true',
                   help='run all end targets in the workflow')
group.add_argument('-t', '--targets', nargs='*', default=[],
                   help='the target(s) to process.')

args = parser.parse_args()

# parse workflow file
workflow = parse(args.workflow_file, args.targets, args.all)

# get a suitable environment for this workflow instance.
environment = get_environment()

# initialize file reporter such that it writes the log file to local
# storage (scratch) until the reporter is finalized.
tmp_dir = os.path.join(environment.scratch_dir, 'jobs', environment.job_id)
final_dir = os.path.join(environment.config_dir, 'jobs', environment.job_id)

reporter = FileReporter(tmp_dir=tmp_dir, final_dir=final_dir)

# construct a directory structure to hold all meta information about this
# workflow instance.
workflow_base = os.path.join(environment.config_dir, environment.job_id)
os.mkdir(workflow_base)
os.mkdir(os.path.join(workflow_base, 'tasks'))

logging.debug('running using %s' % repr(environment))

# initialize a scheduler for the workflow and start the run loop.
scheduler = TaskScheduler(environment,
                          reporter,
                          workflow,
                          ProcessScheduler())
scheduler.run()
