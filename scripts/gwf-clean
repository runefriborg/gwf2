#!/usr/bin/env python

import os
import os.path
import sys
import argparse

from gwf.parser import parse
from gwf.dependency_graph import DependencyGraph


parser = argparse.ArgumentParser(description='Clean workflow files.')
<<<<<<< HEAD
parser.add_argument('workflow_file', help='The .gwf file containing the workflow')
=======

parser.add_argument('-f', '--file',
                    default='workflow.gwf', dest='workflow_file',
                    help='workflow file if not the default (workflow.gwf).')
parser.add_argument('-v', '--verbose', action='store_true', default=False,
                    help='Print a list of the deleted files.')

group = parser.add_mutually_exclusive_group()

group.add_argument('-a', '--all', default=False, action='store_true',
                   help='run all end targets in the workflow')
group.add_argument('-t', '--targets', nargs='+',
                   help='the target(s) to process.')
>>>>>>> feature/integration-tests

args = parser.parse_args()

# parse workflow file
workflow = parse(args.workflow_file)

<<<<<<< HEAD
# Build graph
graph = DependencyGraph(workflow)
workflow.target_names = frozenset(node.task.name for node in graph.end_targets)

# Retrieve the list of all tasks 
tasklist = graph.tasklist(workflow.target_names)

# Remove all output files
for task in tasklist:
    for path in task.output:
        if os.path.exists(path):
            os.remove(path)
            print("Removed " + path)
=======
# If all end targets should be run, we have to figure out what those
# are and set the target names in the workflow.
if args.all:
    graph = DependencyGraph(workflow)
    workflow.target_names = frozenset(node.task.name
                                      for node in graph.end_targets)
else:
    workflow.target_names = args.targets
    # check if all targets that we wish to run have been defined in the
    # workflow.
    for target in workflow.target_names:
        if target not in workflow.targets:
            print >> sys.stderr, 'target %s not found in workflow.' % target
            sys.exit(1)

# For every target name specified by the user, compute its dependencies
# and build a list of all tasks which must be run. self.schedule no
# longer corresponds to the topological sorting of the tasks, but is
# just a list of all tasks that must be run. The scheduler will figure
# out the correct order to run them in.
targets = [workflow.targets[target_name]
           for target_name in workflow.target_names]


def dfs(task):
    if not task.can_execute or task.is_dummy:
        return

    if task.checkpoint or task.name in workflow.target_names:
        for path in task.output:
            if os.path.exists(path):
                if args.verbose:
                    print path
                os.remove(path)

    for _, dep in task.dependencies:
        dfs(dep)

for target in targets:
    dfs(target)
>>>>>>> feature/integration-tests
