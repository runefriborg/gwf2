#!/usr/bin/env python

import os
import os.path
import json
import argparse
import subprocess
import datetime

from gwf.process import RemoteProcess
from gwf.reporting import FileReportReader, FileLikeReportReader

CONFIG_DIR = os.getenv('GWF_CONFIG_DIR', os.path.expanduser('~/.gwf/'))


def get_job_environment(job):
    with open(os.path.join(CONFIG_DIR, 'jobs', job, 'environment')) as f:
        return json.load(f)


def get_job_report(environment, job):
    log_path = os.path.join(CONFIG_DIR, 'jobs', job, 'log')

    if os.path.exists(log_path):
        return FileReportReader(log_path)

    # if the log doesn't exist locally, it must still be on the mother node.
    remote_log_path = os.path.join(environment['scratch_dir'], job, 'log')

    reader = FileLikeReportReader()
    process = RemoteProcess('cat {0}'.format(remote_log_path),
                            host=environment['mother_node'],
                            stdout=subprocess.PIPE)

    process.run()

    for out in process.stdout:
        reader.write(out)
    process.wait()

    return reader


def reports(path):
    def comparator((j1, r1), (j2, r2)):
        if (r1.workflow['completed_at'] is None and
                r2.workflow['completed_at'] is None):
            if j1 == j2:
                return 0
            return -1 if j1 < j2 else 1
        elif r1.workflow['completed_at'] is None:
            return -1
        elif r2.workflow['completed_at'] is None:
            return 1
        else:
            if r1.workflow['completed_at'] == r2.workflow['completed_at']:
                return 0
            elif r1.workflow['completed_at'] < r2.workflow['completed_at']:
                return 1
            else:
                return -1

    reports = []
    for job in os.listdir(os.path.join(CONFIG_DIR, 'jobs')):
        environment = get_job_environment(job)
        reports.append((job, get_job_report(environment, job)))
    return sorted(reports, cmp=comparator)

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('-l', '--list', action='store_true',
                        help='list all previously and currently running jobs')
    parser.add_argument('-j', '--job',
                        help='show status for a specific job')
    parser.add_argument('-t', '--task',
                        help='show states for a specific task of a job')

    args = parser.parse_args()

    if args.list and (args.task or args.job):
        parser.error('argument -l/--list: cannot be used with other arguments.')
    if args.task and not args.job:
        parser.error('argument -j/--job: required by argument -t/--task.')

    for job, report in reports(os.path.join(CONFIG_DIR, 'jobs')):
        workflow_status = 'R'

        # Get status of workflow. If any task or transfer of the
        # workflow has failed, the entire workflow has failed.
        did_workflow_fail = bool(report.workflow['failure'])
        did_task_fail = any(report.tasks[task]['failure'] or
                            report.tasks[task]['transfers'][transfer]['failure']
                            for task in report.tasks
                            for transfer in report.tasks[task]['transfers'])

        if did_workflow_fail or did_task_fail:
            workflow_status = 'F'
        elif report.workflow['completed_at'] is not None:
            workflow_status = 'C'

        if report.workflow['completed_at']:
            completed_at = report.workflow['completed_at']
        else:
            completed_at = datetime.datetime.today()
        duration = completed_at - report.workflow['started_at']

        completed_tasks = len([True for task in report.tasks.values()
                               if task['completed_at'] is not None])

        percentage = 100.0
        try:
            total_tasks = float(len(report.workflow['queued']))
            percentage = completed_tasks / total_tasks * 100.0
        except ZeroDivisionError:
            pass

        template = '{0} {1} {2:>6.2f} {3:>3} {4:>3} {5:>5.0f}% {6}'
        print template.format(job,
                              workflow_status,
                              duration.total_seconds(),
                              completed_tasks,
                              len(report.workflow['queued']),
                              percentage,
                              report.workflow['file'])
